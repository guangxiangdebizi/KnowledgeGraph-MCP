#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¾·å›½å®¶æ—ä¼ä¸šçŸ¥è¯†å›¾è°±æ•°æ®å¯¼å…¥Neo4jæ•°æ®åº“
Author: Assistant
Date: 2024
"""

import pandas as pd
from neo4j import GraphDatabase
import logging
from typing import Dict, List, Any

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class Neo4jImporter:
    """Neo4jæ•°æ®å¯¼å…¥ç±»"""
    
    def __init__(self, uri: str, username: str, password: str):
        """
        åˆå§‹åŒ–Neo4jè¿æ¥
        
        Args:
            uri: Neo4jæ•°æ®åº“URI (ä¾‹å¦‚: "bolt://localhost:7687")
            username: ç”¨æˆ·å (é»˜è®¤: "neo4j")
            password: å¯†ç 
        """
        self.driver = GraphDatabase.driver(uri, auth=(username, password))
        logger.info(f"æˆåŠŸè¿æ¥åˆ°Neo4jæ•°æ®åº“: {uri}")
    
    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.driver:
            self.driver.close()
            logger.info("æ•°æ®åº“è¿æ¥å·²å…³é—­")
    
    def clear_database(self):
        """æ¸…ç©ºæ•°æ®åº“ï¼ˆå¯é€‰æ“ä½œï¼‰"""
        with self.driver.session() as session:
            session.run("MATCH (n) DETACH DELETE n")
            logger.info("æ•°æ®åº“å·²æ¸…ç©º")
    
    def create_constraints(self):
        """åˆ›å»ºçº¦æŸå’Œç´¢å¼•"""
        constraints = [
            "CREATE CONSTRAINT node_id_unique IF NOT EXISTS FOR (n:KnowledgeNode) REQUIRE n.id IS UNIQUE",
            "CREATE INDEX node_name_index IF NOT EXISTS FOR (n:KnowledgeNode) ON (n.name)",
            "CREATE INDEX node_type_index IF NOT EXISTS FOR (n:KnowledgeNode) ON (n.type)"
        ]
        
        with self.driver.session() as session:
            for constraint in constraints:
                try:
                    session.run(constraint)
                    logger.info(f"æˆåŠŸåˆ›å»ºçº¦æŸ/ç´¢å¼•: {constraint}")
                except Exception as e:
                    logger.warning(f"çº¦æŸ/ç´¢å¼•å¯èƒ½å·²å­˜åœ¨: {e}")
    
    def import_nodes(self, nodes_file: str):
        """
        å¯¼å…¥èŠ‚ç‚¹æ•°æ®
        
        Args:
            nodes_file: èŠ‚ç‚¹CSVæ–‡ä»¶è·¯å¾„
        """
        try:
            # è¯»å–CSVæ–‡ä»¶
            nodes_df = pd.read_csv(nodes_file, encoding='utf-8')
            logger.info(f"æˆåŠŸè¯»å–èŠ‚ç‚¹æ–‡ä»¶: {nodes_file}, å…±{len(nodes_df)}ä¸ªèŠ‚ç‚¹")
            
            # æ‰¹é‡å¯¼å…¥èŠ‚ç‚¹
            batch_size = 100
            total_batches = (len(nodes_df) + batch_size - 1) // batch_size
            
            with self.driver.session() as session:
                for i in range(0, len(nodes_df), batch_size):
                    batch = nodes_df[i:i + batch_size]
                    batch_num = i // batch_size + 1
                    
                    # å‡†å¤‡æ‰¹æ¬¡æ•°æ®
                    nodes_data = []
                    for _, row in batch.iterrows():
                        nodes_data.append({
                            'id': row['id'],
                            'name': row['name'],
                            'description': row['description'],
                            'type': row['type']
                        })
                    
                    # æ‰§è¡Œæ‰¹é‡æ’å…¥
                    query = """
                    UNWIND $nodes_data AS node
                    CREATE (n:KnowledgeNode {
                        id: node.id,
                        name: node.name,
                        description: node.description,
                        type: node.type
                    })
                    """
                    
                    session.run(query, nodes_data=nodes_data)
                    logger.info(f"å·²å¯¼å…¥èŠ‚ç‚¹æ‰¹æ¬¡ {batch_num}/{total_batches} ({len(batch)}ä¸ªèŠ‚ç‚¹)")
            
            logger.info(f"æ‰€æœ‰èŠ‚ç‚¹å¯¼å…¥å®Œæˆï¼æ€»è®¡{len(nodes_df)}ä¸ªèŠ‚ç‚¹")
            
        except Exception as e:
            logger.error(f"å¯¼å…¥èŠ‚ç‚¹æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            raise
    
    def import_relationships(self, relationships_file: str):
        """
        å¯¼å…¥å…³ç³»æ•°æ®
        
        Args:
            relationships_file: å…³ç³»CSVæ–‡ä»¶è·¯å¾„
        """
        try:
            # è¯»å–CSVæ–‡ä»¶
            relationships_df = pd.read_csv(relationships_file, encoding='utf-8')
            logger.info(f"æˆåŠŸè¯»å–å…³ç³»æ–‡ä»¶: {relationships_file}, å…±{len(relationships_df)}ä¸ªå…³ç³»")
            
            # æ‰¹é‡å¯¼å…¥å…³ç³»
            batch_size = 100
            total_batches = (len(relationships_df) + batch_size - 1) // batch_size
            
            with self.driver.session() as session:
                for i in range(0, len(relationships_df), batch_size):
                    batch = relationships_df[i:i + batch_size]
                    batch_num = i // batch_size + 1
                    
                    # å‡†å¤‡æ‰¹æ¬¡æ•°æ®
                    relationships_data = []
                    for _, row in batch.iterrows():
                        relationships_data.append({
                            'source_id': row['source_id'],
                            'target_id': row['target_id'],
                            'relationship_type': row['relationship_type'],
                            'description': row['description']
                        })
                    
                    # æ‰§è¡Œæ‰¹é‡åˆ›å»ºå…³ç³»
                    query = """
                    UNWIND $relationships_data AS rel
                    MATCH (source:KnowledgeNode {id: rel.source_id})
                    MATCH (target:KnowledgeNode {id: rel.target_id})
                    CALL apoc.create.relationship(source, rel.relationship_type, {
                        description: rel.description
                    }, target) YIELD rel as relationship
                    RETURN count(relationship)
                    """
                    
                    # å¦‚æœæ²¡æœ‰APOCæ’ä»¶ï¼Œä½¿ç”¨åŸºç¡€è¯­æ³•
                    fallback_query = """
                    UNWIND $relationships_data AS rel
                    MATCH (source:KnowledgeNode {id: rel.source_id})
                    MATCH (target:KnowledgeNode {id: rel.target_id})
                    CREATE (source)-[r:RELATED {
                        type: rel.relationship_type,
                        description: rel.description
                    }]->(target)
                    """
                    
                    try:
                        session.run(query, relationships_data=relationships_data)
                    except:
                        # å¦‚æœAPOCä¸å¯ç”¨ï¼Œä½¿ç”¨fallbackæ–¹æ¡ˆ
                        session.run(fallback_query, relationships_data=relationships_data)
                    
                    logger.info(f"å·²å¯¼å…¥å…³ç³»æ‰¹æ¬¡ {batch_num}/{total_batches} ({len(batch)}ä¸ªå…³ç³»)")
            
            logger.info(f"æ‰€æœ‰å…³ç³»å¯¼å…¥å®Œæˆï¼æ€»è®¡{len(relationships_df)}ä¸ªå…³ç³»")
            
        except Exception as e:
            logger.error(f"å¯¼å…¥å…³ç³»æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            raise
    
    def create_hierarchy_relationships(self):
        """åˆ›å»ºç‰¹å®šçš„å±‚æ¬¡å…³ç³»ï¼ˆCONTAINSå’ŒINCLUDESï¼‰"""
        queries = [
            # åˆ›å»ºCONTAINSå…³ç³»
            """
            MATCH (source:KnowledgeNode)-[r:RELATED]->(target:KnowledgeNode)
            WHERE r.type = 'CONTAINS'
            CREATE (source)-[:CONTAINS {description: r.description}]->(target)
            """,
            # åˆ›å»ºINCLUDESå…³ç³»
            """
            MATCH (source:KnowledgeNode)-[r:RELATED]->(target:KnowledgeNode)
            WHERE r.type = 'INCLUDES'
            CREATE (source)-[:INCLUDES {description: r.description}]->(target)
            """,
            # åˆ é™¤é€šç”¨RELATEDå…³ç³»
            """
            MATCH ()-[r:RELATED]->()
            DELETE r
            """
        ]
        
        with self.driver.session() as session:
            for query in queries:
                session.run(query)
            logger.info("å·²åˆ›å»ºå±‚æ¬¡å…³ç³»å¹¶æ¸…ç†é€šç”¨å…³ç³»")
    
    def verify_import(self):
        """éªŒè¯å¯¼å…¥ç»“æœ"""
        with self.driver.session() as session:
            # ç»Ÿè®¡èŠ‚ç‚¹æ•°é‡
            node_count = session.run("MATCH (n:KnowledgeNode) RETURN count(n) as count").single()["count"]
            
            # ç»Ÿè®¡å…³ç³»æ•°é‡
            rel_count = session.run("MATCH ()-[r]->() RETURN count(r) as count").single()["count"]
            
            # æŒ‰ç±»å‹ç»Ÿè®¡èŠ‚ç‚¹
            type_stats = session.run("""
                MATCH (n:KnowledgeNode) 
                RETURN n.type as type, count(n) as count 
                ORDER BY count DESC
            """)
            
            logger.info(f"å¯¼å…¥éªŒè¯ç»“æœ:")
            logger.info(f"- æ€»èŠ‚ç‚¹æ•°: {node_count}")
            logger.info(f"- æ€»å…³ç³»æ•°: {rel_count}")
            logger.info(f"- æŒ‰ç±»å‹ç»Ÿè®¡:")
            
            for record in type_stats:
                logger.info(f"  {record['type']}: {record['count']}ä¸ªèŠ‚ç‚¹")

def main():
    """ä¸»å‡½æ•°"""
    # Neo4jè¿æ¥é…ç½®
    NEO4J_URI = "bolt://localhost:7687"  # æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹
    NEO4J_USERNAME = "neo4j"
    NEO4J_PASSWORD = "chenxingyu"  # è¯·ä¿®æ”¹ä¸ºæ‚¨çš„å¯†ç 
    
    # CSVæ–‡ä»¶è·¯å¾„
    NODES_FILE = "knowledge_graph_nodes.csv"
    RELATIONSHIPS_FILE = "knowledge_graph_relationships.csv"
    
    importer = None
    try:
        # åˆ›å»ºå¯¼å…¥å™¨å®ä¾‹
        importer = Neo4jImporter(NEO4J_URI, NEO4J_USERNAME, NEO4J_PASSWORD)
        
        # è¯¢é—®æ˜¯å¦æ¸…ç©ºæ•°æ®åº“
        clear_db = input("æ˜¯å¦æ¸…ç©ºç°æœ‰æ•°æ®åº“? (y/N): ").lower().strip()
        if clear_db == 'y':
            importer.clear_database()
        
        # åˆ›å»ºçº¦æŸå’Œç´¢å¼•
        importer.create_constraints()
        
        # å¯¼å…¥èŠ‚ç‚¹
        logger.info("å¼€å§‹å¯¼å…¥èŠ‚ç‚¹...")
        importer.import_nodes(NODES_FILE)
        
        # å¯¼å…¥å…³ç³»
        logger.info("å¼€å§‹å¯¼å…¥å…³ç³»...")
        importer.import_relationships(RELATIONSHIPS_FILE)
        
        # åˆ›å»ºå±‚æ¬¡å…³ç³»
        logger.info("åˆ›å»ºå±‚æ¬¡å…³ç³»...")
        importer.create_hierarchy_relationships()
        
        # éªŒè¯å¯¼å…¥ç»“æœ
        logger.info("éªŒè¯å¯¼å…¥ç»“æœ...")
        importer.verify_import()
        
        logger.info("ğŸ‰ å¾·å›½å®¶æ—ä¼ä¸šçŸ¥è¯†å›¾è°±å¯¼å…¥å®Œæˆï¼")
        logger.info("ğŸ’¡ æ‚¨å¯ä»¥åœ¨Neo4j Browserä¸­ä½¿ç”¨ä»¥ä¸‹æŸ¥è¯¢è¯­å¥æ¢ç´¢æ•°æ®ï¼š")
        logger.info("   - æŸ¥çœ‹æ‰€æœ‰èŠ‚ç‚¹: MATCH (n) RETURN n LIMIT 25")
        logger.info("   - æŸ¥çœ‹æ ¹èŠ‚ç‚¹åŠå…¶å­èŠ‚ç‚¹: MATCH (root {id: 'root'})-[:CONTAINS]->(child) RETURN root, child")
        logger.info("   - æŒ‰ç±»å‹æŸ¥çœ‹èŠ‚ç‚¹: MATCH (n:KnowledgeNode) WHERE n.type = 'ç¬¬ä¸€éƒ¨åˆ†' RETURN n")
        
    except Exception as e:
        logger.error(f"å¯¼å…¥è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return 1
    
    finally:
        if importer:
            importer.close()
    
    return 0

if __name__ == "__main__":
    exit(main()) 